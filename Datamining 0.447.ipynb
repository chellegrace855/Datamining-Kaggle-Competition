{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c68b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T13:55:37.288479Z",
     "iopub.status.busy": "2024-12-13T13:55:37.288227Z",
     "iopub.status.idle": "2024-12-13T13:55:55.156182Z",
     "shell.execute_reply": "2024-12-13T13:55:55.155493Z"
    },
    "papermill": {
     "duration": 17.873271,
     "end_time": "2024-12-13T13:55:55.158132",
     "exception": false,
     "start_time": "2024-12-13T13:55:37.284861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed579f",
   "metadata": {
    "papermill": {
     "duration": 0.001816,
     "end_time": "2024-12-13T13:55:55.162502",
     "exception": false,
     "start_time": "2024-12-13T13:55:55.160686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c1ff2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T13:55:55.168003Z",
     "iopub.status.busy": "2024-12-13T13:55:55.167183Z",
     "iopub.status.idle": "2024-12-13T13:56:35.640112Z",
     "shell.execute_reply": "2024-12-13T13:56:35.638977Z"
    },
    "papermill": {
     "duration": 40.479823,
     "end_time": "2024-12-13T13:56:35.644232",
     "exception": false,
     "start_time": "2024-12-13T13:55:55.164409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.7)\r\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.3)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.5)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.14.1)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.22.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.3.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41b6990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T13:56:35.650500Z",
     "iopub.status.busy": "2024-12-13T13:56:35.650224Z",
     "iopub.status.idle": "2024-12-13T13:56:35.753380Z",
     "shell.execute_reply": "2024-12-13T13:56:35.752747Z"
    },
    "papermill": {
     "duration": 0.108521,
     "end_time": "2024-12-13T13:56:35.755119",
     "exception": false,
     "start_time": "2024-12-13T13:56:35.646598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "import numpy as np\n",
    "SEED = 42\n",
    "n_splits = 5\n",
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "def preprocess_train_data(data):\n",
    "\n",
    "    # Drop 'id' and separate numeric and categorical data\n",
    "\n",
    "    data_no_id = data.drop(columns=['id'])\n",
    "    data_no_id = data_no_id[data_no_id['Physical-Systolic_BP'] > data_no_id['Physical-Diastolic_BP']].reset_index(drop=True)\n",
    "    data_no_id = data_no_id[(data_no_id['Physical-Systolic_BP'] - data_no_id['Physical-Diastolic_BP'])> 25].reset_index(drop=True)\n",
    "    numeric_data = data_no_id.select_dtypes(include=['number']).copy()\n",
    "\n",
    "    categorical_data = data_no_id.select_dtypes(exclude=['number']).copy()\n",
    "\n",
    "    \n",
    "\n",
    "    # Drop PCIAT-PCIAT_Total and sii before applying KNN\n",
    "\n",
    "    numeric_data = numeric_data.drop(columns=['PCIAT-PCIAT_Total', 'sii'], errors='ignore')\n",
    "\n",
    "    \n",
    "\n",
    "    # Impute categorical data with mode\n",
    "\n",
    "    for col in categorical_data.columns:\n",
    "\n",
    "        categorical_data[col].fillna(categorical_data[col].mode()[0], inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Encode categorical data\n",
    "\n",
    "    encoder = OrdinalEncoder()\n",
    "\n",
    "    categorical_encoded = encoder.fit_transform(categorical_data)\n",
    "\n",
    "    categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=categorical_data.columns)\n",
    "\n",
    "    \n",
    "\n",
    "    # Apply KNN Imputer to numeric data\n",
    "\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    numeric_imputed = pd.DataFrame(knn_imputer.fit_transform(numeric_data), columns=numeric_data.columns)\n",
    "\n",
    "    \n",
    "\n",
    "    # Round PCIAT-PCIAT_[num] columns and calculate PCIAT-PCIAT_Total\n",
    "\n",
    "    pciat_columns = [col for col in numeric_imputed.columns if col.startswith('PCIAT-PCIAT_')]\n",
    "\n",
    "    for col in pciat_columns:\n",
    "\n",
    "        numeric_imputed[col] = numeric_imputed[col].round().astype(int)\n",
    "\n",
    "    numeric_imputed['PCIAT-PCIAT_Total'] = numeric_imputed[pciat_columns].sum(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    # Determine sii based on PCIAT-PCIAT_Total\n",
    "\n",
    "    def calculate_sii(total):\n",
    "\n",
    "        if total <= 30:\n",
    "\n",
    "            return 0  # None\n",
    "\n",
    "        elif 31 <= total <= 49:\n",
    "\n",
    "            return 1  # Mild\n",
    "\n",
    "        elif 50 <= total <= 79:\n",
    "\n",
    "            return 2  # Moderate\n",
    "\n",
    "        else:\n",
    "\n",
    "            return 3  # Severe\n",
    "\n",
    "\n",
    "\n",
    "    numeric_imputed['sii'] = numeric_imputed['PCIAT-PCIAT_Total'].apply(calculate_sii)\n",
    "\n",
    "\n",
    "\n",
    "    # Combine numeric and categorical data\n",
    "\n",
    "    processed_data = pd.concat([data['id'].reset_index(drop=True), numeric_imputed, categorical_encoded_df], axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "\n",
    "# Function to preprocess test data\n",
    "\n",
    "def preprocess_test_data(data):\n",
    "\n",
    "    # Drop 'id' and separate numeric and categorical data\n",
    "\n",
    "    data_no_id = data.drop(columns=['id'])\n",
    "\n",
    "    numeric_data = data_no_id.select_dtypes(include=['number']).copy()\n",
    "\n",
    "    categorical_data = data_no_id.select_dtypes(exclude=['number']).copy()\n",
    "\n",
    "    \n",
    "\n",
    "    # Impute categorical data with mode\n",
    "\n",
    "    for col in categorical_data.columns:\n",
    "\n",
    "        categorical_data[col].fillna(categorical_data[col].mode()[0], inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Encode categorical data\n",
    "\n",
    "    encoder = OrdinalEncoder()\n",
    "\n",
    "    categorical_encoded = encoder.fit_transform(categorical_data)\n",
    "\n",
    "    categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=categorical_data.columns)\n",
    "\n",
    "    \n",
    "\n",
    "    # Apply KNN Imputer to numeric data\n",
    "\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    numeric_imputed = pd.DataFrame(knn_imputer.fit_transform(numeric_data), columns=numeric_data.columns)\n",
    "\n",
    "\n",
    "\n",
    "    # Combine numeric and categorical data\n",
    "\n",
    "    processed_data = pd.concat([data['id'].reset_index(drop=True), numeric_imputed, categorical_encoded_df], axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    return processed_data\n",
    "def feature_engineering(df, training):\n",
    "    season_cols = [col for col in df.columns if 'Season' in col]\n",
    "    df = df.drop(season_cols, axis=1) \n",
    "    df['BMI_Average'] = df[['Physical-BMI', 'BIA-BIA_BMI']].mean(axis=1)\n",
    "    df['Fitness_Endurance_Time_Total_Sec'] = df['Fitness_Endurance-Time_Mins'] * 60 + df['Fitness_Endurance-Time_Sec']\n",
    "    df.drop(['Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec'], axis=1, inplace=True)\n",
    "    df.drop(['Physical-BMI', 'BIA-BIA_BMI'], axis=1, inplace=True)\n",
    "    if training:\n",
    "        pciat_questions = [f'PCIAT-PCIAT_{i:02d}' for i in range(1, 21)]\n",
    "        df.drop(pciat_questions, axis=1, inplace=True)\n",
    "        df.drop('PCIAT-PCIAT_Total', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869a40ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T13:56:35.760788Z",
     "iopub.status.busy": "2024-12-13T13:56:35.760551Z",
     "iopub.status.idle": "2024-12-13T13:57:49.496422Z",
     "shell.execute_reply": "2024-12-13T13:57:49.495381Z"
    },
    "papermill": {
     "duration": 73.740695,
     "end_time": "2024-12-13T13:57:49.498094",
     "exception": false,
     "start_time": "2024-12-13T13:56:35.757399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:10<00:00, 14.06it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2848, 143)\n",
      "(20, 142)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = preprocess_train_data(train)\n",
    "train = feature_engineering(train, True)\n",
    "test = preprocess_test_data(test)\n",
    "test = feature_engineering(test, False)\n",
    "\n",
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop(columns=['id'], axis=1)\n",
    "test = test.drop(columns=['id'], axis=1)   \n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', \n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', \n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train.dropna(subset='sii')\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf24bebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T13:57:49.530045Z",
     "iopub.status.busy": "2024-12-13T13:57:49.529600Z",
     "iopub.status.idle": "2024-12-13T13:57:49.540643Z",
     "shell.execute_reply": "2024-12-13T13:57:49.539997Z"
    },
    "papermill": {
     "duration": 0.02871,
     "end_time": "2024-12-13T13:57:49.542302",
     "exception": false,
     "start_time": "2024-12-13T13:57:49.513592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d6c06c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T13:57:49.572458Z",
     "iopub.status.busy": "2024-12-13T13:57:49.572211Z",
     "iopub.status.idle": "2024-12-13T13:58:27.384038Z",
     "shell.execute_reply": "2024-12-13T13:58:27.383175Z"
    },
    "papermill": {
     "duration": 37.828742,
     "end_time": "2024-12-13T13:58:27.385651",
     "exception": false,
     "start_time": "2024-12-13T13:57:49.556909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:37<00:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7767\n",
      "Mean Validation QWK ---> 0.4256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.489\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model parameters for LightGBM\n",
    "LGBM_Params = {\n",
    "    'learning_rate': 0.046,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 478,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'feature_fraction': 0.893,\n",
    "    'bagging_fraction': 0.784,\n",
    "    'bagging_freq': 4,\n",
    "    'lambda_l1': 10,  \n",
    "    'lambda_l2': 0.01  \n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,  \n",
    "    'reg_lambda': 5,  \n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'iterations': 200,\n",
    "    'random_seed': SEED,\n",
    "    'verbose': 0,\n",
    "    'l2_leaf_reg': 10  # Increase this value\n",
    "}\n",
    "\n",
    "# Create model instances\n",
    "Light = LGBMRegressor(**LGBM_Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGB_Model = XGBRegressor(**XGB_Params)\n",
    "CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "\n",
    "# Combine models using Voting Regressor\n",
    "voting_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', Light),\n",
    "    ('xgboost', XGB_Model),\n",
    "    ('catboost', CatBoost_Model)\n",
    "])\n",
    "\n",
    "# Train the ensemble model\n",
    "Submission2 = TrainML(voting_model, test)\n",
    "\n",
    "Submission2.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 175.709063,
   "end_time": "2024-12-13T13:58:30.671689",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-13T13:55:34.962626",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
